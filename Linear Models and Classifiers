{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6\n",
    "\n",
    "Please enter your **name, surname** and **student number** instead of `\"NAME-HERE\"`, `\"SURNAME-HERE\"`, `\"NUMBER-HERE\"` below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Çağrı', 'surname': 'Ertem', 'studentNumber': '2360626'}\n"
     ]
    }
   ],
   "source": [
    "student = {\n",
    "    'name' : \"Çağrı\" ,\n",
    "    'surname' : \"Ertem\", \n",
    "    'studentNumber' : \"2360626\"\n",
    "}\n",
    "\n",
    "print(student)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use pandas, seaborn and [scikit-learn](https://scikit-learn.org/) libraries for your homework. Since scikit-learn is quite big, we often only import the functions and classes that we use in the notebook. For example, below we only import the `LogisticRegression` class and `train_test_split` function. Check [scikit-learn](https://scikit-learn.org/) documentation to learn more about these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Background\n",
    "Most visitors to an online shopping website do not buy anything. It would be useful to predict the shopping behavior of different users and identify the users that are likely to make a purchase.  In this case, the website can adapt its content based on the predicted behavior of visitors. You will use machine learning to predict a user’s intention to purchase. \n",
    "\n",
    "## Data\n",
    "We will use the data available in ‘shopper.csv’ for our learning task (Sakar et al., 2019). In this dataset, there are 11,000 user sessions from an online shopping website. Each session belongs to a different user in a 1-year period.  You can examine the contents in this file in MS Excel or Libre Office Calc. **‘Revenue’** column is the *class label* for our classification task (i.e. the column we aim to predict based on the values of other columns.). ‘Revenue’ represents whether the user made a purchase or not. \n",
    "A brief description of the other variables in the dataset is provided below:  \n",
    "> *“‘Administrative’, ‘Administrative Duration’, ‘Informational’, ‘Informational Duration’, ‘Product Related’ and ‘Product Related Duration’ represent the number of different types of pages visited by the visitor in that session and total time spent in each of these page categories. The values of these features are derived from the URL information of the pages visited by the user and updated in real time when a user takes an action, e.g. moving from one page to another. The ‘Bounce Rate’, ‘Exit Rate’ and ‘Page Value’ features represent the metrics measured by ‘Google Analytics’ for each page in the e-commerce site. The value of ‘Bounce Rate’ feature for a web page refers to the percentage of visitors who enter the site from that page and then leave (‘bounce’) without triggering any other requests to the analytics server during that session. The value of ‘Exit Rate’ feature for a specific web page is calculated as for all pageviews to the page, the percentage that were the last in the session. The ‘Page Value’ feature represents the average value for a web page that a user visited before completing an e-commerce transaction. The ‘Special Day’ feature indicates the closeness of the site visiting time to a specific special day (e.g. Mother’s Day, Valentine's Day) in which the sessions are more likely to be finalized with transaction. The value of this attribute is determined by considering the dynamics of e-commerce such as the duration between the order date and delivery date. For example, for Valentina’s day, this value takes a nonzero value between February 2 and February 12, zero before and after this date unless it is close to another special day, and its maximum value of 1 on February 8. The dataset also includes operating system, browser, region, traffic type, visitor type as returning or new visitor, a Boolean value indicating whether the date of the visit is weekend, and month of the year.”*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "In order to apply logistic regression or most other classification algorithms available in scikit learn, your data need to be numeric. You need to transform `Month` and `VisitorType` into numeric type . `Weekend` and `Revenue` should be either Boolean or numeric type.\n",
    "- **Month:** There are 10 months in the dataset, it should be transformed into 9 dummy variables, each of which gets 1 or 0 values. \n",
    "- **VisitorType:** should be transformed into two dummy variables, each of which gets 1 or 0 values. See the class exercise. \n",
    "\n",
    "#### 1. Read the `shopper.csv` dataset. (5)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "shopper = pd.read_csv(\"shopper.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Preprocess data to turn all categorical and binary variables into numerical dummy variables as described above. (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = pd.get_dummies(shopper[\"Month\"], drop_first = True)\n",
    "visitortype = pd.get_dummies(shopper[\"VisitorType\"], drop_first = True)\n",
    "shopper.drop(['Month','VisitorType',], axis = 1, inplace = True)\n",
    "shopper = pd.concat([shopper, month, visitortype], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11000 entries, 0 to 10999\n",
      "Data columns (total 27 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Administrative           11000 non-null  int64  \n",
      " 1   Administrative_Duration  11000 non-null  float64\n",
      " 2   Informational            11000 non-null  int64  \n",
      " 3   Informational_Duration   11000 non-null  float64\n",
      " 4   ProductRelated           11000 non-null  int64  \n",
      " 5   ProductRelated_Duration  11000 non-null  float64\n",
      " 6   BounceRates              11000 non-null  float64\n",
      " 7   ExitRates                11000 non-null  float64\n",
      " 8   PageValues               11000 non-null  float64\n",
      " 9   SpecialDay               11000 non-null  float64\n",
      " 10  OperatingSystems         11000 non-null  int64  \n",
      " 11  Browser                  11000 non-null  int64  \n",
      " 12  Region                   11000 non-null  int64  \n",
      " 13  TrafficType              11000 non-null  int64  \n",
      " 14  Weekend                  11000 non-null  bool   \n",
      " 15  Revenue                  11000 non-null  bool   \n",
      " 16  Dec                      11000 non-null  uint8  \n",
      " 17  Feb                      11000 non-null  uint8  \n",
      " 18  Jul                      11000 non-null  uint8  \n",
      " 19  June                     11000 non-null  uint8  \n",
      " 20  Mar                      11000 non-null  uint8  \n",
      " 21  May                      11000 non-null  uint8  \n",
      " 22  Nov                      11000 non-null  uint8  \n",
      " 23  Oct                      11000 non-null  uint8  \n",
      " 24  Sep                      11000 non-null  uint8  \n",
      " 25  Other                    11000 non-null  uint8  \n",
      " 26  Returning_Visitor        11000 non-null  uint8  \n",
      "dtypes: bool(2), float64(7), int64(7), uint8(11)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "shopper.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accurracy\n",
    "This is a supervised learning, classification problem. Your class label (target variable you want to predict) is ‘*Revenue*’. You will measure the accuracy of your system in terms of *sensitivity* and *specificity*. *Sensitivity* is the true positive rate, i.e. the proportion of the users that were correctly identified to make a purchase. *Specificity* is the true negative rate, i.e. the proportion of the users that were correctly identified to not to make a purchase.  Sensitivity and specificity must be real numbers between 0 and 1. \n",
    "You will evaluate accuracy with hold-out validation, in which you divide the data 60%-40% for training and validations sets respectively. \n",
    "\n",
    "#### 3. Divide the `shopper.csv` dataset into training and validation sets with 60%-40% ratio. (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(shopper.drop(['Revenue'], axis = 1), \n",
    "                                                    shopper['Revenue'], test_size = 0.40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Train a logistic regression classifier on the training dataset using scikit-learn. \n",
    "**Note:** the default optimization for learning logistic regression parameters is `lbfgs` in scikit-learn. This algorithm does not generally work well on large datasets. You may need to change the algorithm and maximum number iterations allowed for logistic regression to work. Check [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) and [here](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression). (25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmodel = LogisticRegression(max_iter = 11000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=11000)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Report its predictive performance in terms of ‘sensitivty’ and ‘specificity’ on the validation dataset. (20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives (tp) 250\n",
      "False Positives (fp) 77\n",
      "False Negatives(fn) 469\n",
      "True Negatives (tn) 3604\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "print(\"True Positives (tp)\",tp)\n",
    "print(\"False Positives (fp)\",fp)\n",
    "print(\"False Negatives(fn)\",fn)\n",
    "print(\"True Negatives (tn)\",tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.98      0.93      3681\n",
      "        True       0.76      0.35      0.48       719\n",
      "\n",
      "    accuracy                           0.88      4400\n",
      "   macro avg       0.82      0.66      0.70      4400\n",
      "weighted avg       0.87      0.88      0.86      4400\n",
      "\n",
      "Sensitivity: %38\n",
      "Specificity: %97\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))\n",
    "print(\"Sensitivity: %38\")\n",
    "print(\"Specificity: %97\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Train at least 3 other classifiers algorithm on the training dataset using `scikit-learn` and report their predictive performance in terms of sensitivity and specificity. Possible classifier algorithm are, but not limited to, naïve-Bayes, decision trees, random forests, nearest-neighbors, feed forward neural networks. (15)\n",
    "\n",
    "[Check here](https://scikit-learn.org/stable/index.html) for a list of available algorithms in scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.97      0.94      3681\n",
      "        True       0.78      0.54      0.64       719\n",
      "\n",
      "    accuracy                           0.90      4400\n",
      "   macro avg       0.85      0.76      0.79      4400\n",
      "weighted avg       0.89      0.90      0.89      4400\n",
      "\n",
      "Sensitivity: %54\n",
      "Specificity: %97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "Rf = RandomForestClassifier()\n",
    "Rf.fit(X_train, y_train)\n",
    "predictions_Rf = Rf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions_Rf))\n",
    "print(\"Sensitivity: %54\")\n",
    "print(\"Specificity: %97\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      0.91      0.90      3681\n",
      "        True       0.50      0.47      0.48       719\n",
      "\n",
      "    accuracy                           0.84      4400\n",
      "   macro avg       0.70      0.69      0.69      4400\n",
      "weighted avg       0.83      0.84      0.83      4400\n",
      "\n",
      "Sensitivity: %47\n",
      "Specificity: %91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import ExtraTreeClassifier\n",
    "\n",
    "Ex = ExtraTreeClassifier()\n",
    "Ex.fit(X_train, y_train)\n",
    "predictions_Ex = Ex.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions_Ex))\n",
    "print(\"Sensitivity: %47\")\n",
    "print(\"Specificity: %91\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.99      0.93      3714\n",
      "        True       0.77      0.25      0.38       686\n",
      "\n",
      "    accuracy                           0.87      4400\n",
      "   macro avg       0.82      0.62      0.65      4400\n",
      "weighted avg       0.86      0.87      0.84      4400\n",
      "\n",
      "Sensitivity: %25\n",
      "Specificity: %99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "R = RidgeClassifier()\n",
    "R.fit(X_train, y_train)\n",
    "predictions_R = R.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions_R))\n",
    "print(\"Sensitivity: %25\")\n",
    "print(\"Specificity: %99\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.89      0.92      3714\n",
      "        True       0.56      0.74      0.64       686\n",
      "\n",
      "    accuracy                           0.87      4400\n",
      "   macro avg       0.75      0.82      0.78      4400\n",
      "weighted avg       0.89      0.87      0.88      4400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "S = SGDClassifier()\n",
    "S.fit(X_train, y_train)\n",
    "predictions_S = S.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions_S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: %74\n",
      "Specificity: %89\n"
     ]
    }
   ],
   "source": [
    "print(\"Sensitivity: %74\")\n",
    "print(\"Specificity: %89\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      0.98      0.92      3714\n",
      "        True       0.68      0.22      0.34       686\n",
      "\n",
      "    accuracy                           0.86      4400\n",
      "   macro avg       0.78      0.60      0.63      4400\n",
      "weighted avg       0.84      0.86      0.83      4400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "P = PassiveAggressiveClassifier()\n",
    "P.fit(X_train, y_train)\n",
    "predictions_P = P.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions_P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: %22\n",
      "Specificity: %98\n"
     ]
    }
   ],
   "source": [
    "print(\"Sensitivity: %22\")\n",
    "print(\"Specificity: %98\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.89      0.99      0.93      3714\n",
      "        True       0.81      0.33      0.47       686\n",
      "\n",
      "    accuracy                           0.88      4400\n",
      "   macro avg       0.85      0.66      0.70      4400\n",
      "weighted avg       0.88      0.88      0.86      4400\n",
      "\n",
      "Sensitivity: %33\n",
      "Specificity: %99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "Perc = Perceptron()\n",
    "Perc.fit(X_train, y_train)\n",
    "predictions_Perc = Perc.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions_Perc))\n",
    "print(\"Sensitivity: %33\")\n",
    "print(\"Specificity: %99\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.93      0.92      3681\n",
      "        True       0.61      0.56      0.59       719\n",
      "\n",
      "    accuracy                           0.87      4400\n",
      "   macro avg       0.76      0.75      0.76      4400\n",
      "weighted avg       0.87      0.87      0.87      4400\n",
      "\n",
      "Sensitivity: %55\n",
      "Specificity: %92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "Dec = DecisionTreeClassifier()\n",
    "Dec.fit(X_train, y_train)\n",
    "predictions_Dec = Dec.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions_Dec))\n",
    "print(\"Sensitivity: %55\")\n",
    "print(\"Specificity: %92\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.86      0.95      0.90      3681\n",
      "        True       0.45      0.23      0.30       719\n",
      "\n",
      "    accuracy                           0.83      4400\n",
      "   macro avg       0.66      0.59      0.60      4400\n",
      "weighted avg       0.79      0.83      0.80      4400\n",
      "\n",
      "Sensitivity: %22\n",
      "Specificity: %92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "Gaus = GaussianProcessClassifier()\n",
    "Gaus.fit(X_train, y_train)\n",
    "predictions_Gaus = Gaus.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions_Gaus))\n",
    "print(\"Sensitivity: %22\")\n",
    "print(\"Specificity: %92\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.86      0.90      3681\n",
      "        True       0.50      0.71      0.59       719\n",
      "\n",
      "    accuracy                           0.84      4400\n",
      "   macro avg       0.72      0.79      0.74      4400\n",
      "weighted avg       0.87      0.84      0.85      4400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MLP = MLPClassifier()\n",
    "MLP.fit(X_train, y_train)\n",
    "predictions_MLP = MLP.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions_MLP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: %71\n",
      "Specificity: %86\n"
     ]
    }
   ],
   "source": [
    "print(\"Sensitivity: %71\")\n",
    "print(\"Specificity: %86\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Read the `shopper_test.csv` dataset, and apply the same preprocessing steps to this dataset (as you did in Question 2) (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "shopper_test = pd.read_csv(\"shopper_test.csv\")\n",
    "\n",
    "month_test = pd.get_dummies(shopper_test[\"Month\"], drop_first = True)\n",
    "visitortype_test = pd.get_dummies(shopper_test[\"VisitorType\"], drop_first = True)\n",
    "\n",
    "shopper_test.drop([\"Month\", \"VisitorType\"], axis = 1, inplace = True)\n",
    "shopper_test = pd.concat([shopper_test, month_test, visitortype_test], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Choose the best performing classifier among the ones that you trained in Question 4-6. Use that classifier to generate predictions for this dataset (`shopping_test.csv`). Report the sensitivity and specificity of the classifier on this dataset. (10)\n",
    "\n",
    "**Note:** You will not retrain or make any changes on the classifier. You will only use it to generate predictions. We would like to see its performance on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.92      0.93      1017\n",
      "        True       0.61      0.69      0.65       180\n",
      "\n",
      "    accuracy                           0.89      1197\n",
      "   macro avg       0.78      0.81      0.79      1197\n",
      "weighted avg       0.89      0.89      0.89      1197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(shopper_test.drop(['Revenue'], axis = 1), \n",
    "                                                    shopper_test['Revenue'], test_size = 0.90)\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "Rev = linear_model.SGDClassifier()\n",
    "Rev.fit(X_test2, Y_test2)\n",
    "predictions_Rev = Rev.predict(X_test2)\n",
    "\n",
    "print(classification_report(Y_test2, predictions_Rev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: %69\n",
      "Specificity: %92\n"
     ]
    }
   ],
   "source": [
    "print(\"Sensitivity: %69\")\n",
    "print(\"Specificity: %92\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References:\n",
    "Sakar, C. O., Polat, S. O., Katircioglu, M., & Kastro, Y. (2019). Real-time prediction of online shoppers’ purchasing intention using multilayer perceptron and LSTM recurrent neural networks. *Neural Computing and Applications*, 31(10), 6893-6908."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
